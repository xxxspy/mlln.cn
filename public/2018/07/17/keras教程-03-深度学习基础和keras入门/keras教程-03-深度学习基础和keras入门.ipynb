{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: keras教程-03-深度学习基础和keras入门\n",
    "date: 2018-07-17 20:17:55\n",
    "tags: [keras教程]\n",
    "toc: true\n",
    "xiongzhang: true\n",
    "mathjax: true\n",
    "\n",
    "---\n",
    "<span></span>\n",
    "<!-- more -->\n",
    "\n",
    "> 声明: 本文由[DataScience](http://mlln.cn)编辑发表, 转载请注明[本文链接](http://mlln.cn)mlln.cn, 并在文后留言`转载`.\n",
    "\n",
    "本文代码运行环境:\n",
    "\n",
    "- windows10\n",
    "- python3.6\n",
    "- jupyter notebook\n",
    "- tensorflow 1.x\n",
    "- keras 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 感知器\n",
    "\n",
    "<img src=\"images/perception-map.png\" />\n",
    "\n",
    "<center>图1 感知器模型</center>\n",
    "\n",
    "\n",
    "\n",
    "感知器是一种简单的算法，输入是一个向量$x$, 向量$x$由$m$个数构成$(x_1，x_2，...，x_n)$，通常称为输入特征或简单特征，输出是1或0。在数学上，我们定义感知器为：\n",
    "\n",
    "第一部计算输入值, $z和b$都是一个实数, $wx$代表点积$\\sum_{j=1}w_j x_j $\n",
    "\n",
    "$$\n",
    "z = wx + b\n",
    "$$\n",
    "\n",
    "第二步计算激活量, 下面的函数可以被称为激活函数。\n",
    "\n",
    "$$\n",
    "f(x) = \\left\\{ \n",
    "\\begin{aligned}\n",
    "1 ; & if  z >0 & \\\\\n",
    "0 ; & if z <=0 & \\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "> **注:**感知器像是一个线性回归模型, 只是输出值只有1和0。\n",
    "\n",
    "#### 感知器激活函数\n",
    "\n",
    "<img src=\"images/perception.png\" />\n",
    "<center>图2 激活函数</center>\n",
    "\n",
    "\n",
    "这样的激活函数有一个主要的问题是, 函数不是平滑的, 导致机器学习过程中, 权重w和偏差b很难找到合适的调整方向, 增加学习的难度。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 激活函数平滑化\n",
    "\n",
    "<img src=\"images/sigmoid-tanh.png\" />\n",
    "<center>图3 sigmoid和tanh激活函数</center>\n",
    "\n",
    "##### sigmoid函数\n",
    "\n",
    "它能够把输入的连续实值“压缩”到0和1之间。 \n",
    "特别的，如果是非常大的负数，那么输出就是0；如果是非常大的正数，输出就是1. \n",
    "sigmoid 函数曾经被使用的很多，不过近年来，用它的人越来越少了。主要是因为它的一些 缺点：\n",
    "\n",
    "- Sigmoids saturate and kill gradients. sigmoid 有一个非常致命的缺点，当输入非常大或者非常小的时候（saturation），这些神经元的梯度是接近于0的，从图中可以看出梯度的趋势。所以，你需要尤其注意参数的初始值来尽量避免saturation的情况。如果你的初始值很大的话，大部分神经元可能都会处在saturation的状态而把gradient kill掉，这会导致网络变的很难学习。\n",
    "\n",
    "- Sigmoid 的 output 不是0均值. 这是不可取的，因为这会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。 产生的一个结果就是：如果数据进入神经元的时候是正的(e.g. x>0 elementwise in f=wTx+b)，那么 w 计算出的梯度也会始终都是正的。 当然了，如果你是按batch去训练，那么那个batch可能得到不同的信号，所以这个问题还是可以缓解一下的。因此，非0均值这个问题虽然会产生一些不好的影响，不过跟上面提到的 kill gradients 问题相比还是要好很多的。\n",
    "\n",
    "\n",
    "##### tanh函数\n",
    "\n",
    "tanh 是上图中的右图，可以看出，tanh 跟sigmoid还是很像的，实际上，tanh 是sigmoid的变形。tanh优于sigmoid的地方在于它的输出是均值为0的。\n",
    "\n",
    "##### relu函数\n",
    "\n",
    "<img src=\"images/relu.png\" />\n",
    "\n",
    "relu函数近年来越来越火, 它的函数形式如下:\n",
    "\n",
    "$$\n",
    "f(x) = max(0, x)\n",
    "$$\n",
    "\n",
    "ReLU 的优点：\n",
    "\n",
    "Krizhevsky et al. 发现使用 ReLU 得到的SGD的收敛速度会比 sigmoid/tanh 快很多(看右图)。有人说这是因为它是linear，而且 non-saturating\n",
    "相比于 sigmoid/tanh，ReLU 只需要一个阈值就可以得到激活值，而不用去算一大堆复杂的运算。\n",
    "\n",
    "ReLU 的缺点： 当然 ReLU 也有缺点，就是训练的时候很”脆弱”，很容易就”die”了. 什么意思呢？举个例子：一个非常大的梯度流过一个 ReLU 神经元，更新过参数之后，这个神经元再也不会对任何数据有激活现象了。实际操作中，如果你的learning rate 很大，那么很有可能你网络中的40%的神经元都”dead”了。 当然，如果你设置了一个合适的较小的learning rate，这个问题发生的情况其实也不会太频繁。所以, Relu实际上是非常推荐的激活函数。\n",
    "\n",
    "##### softmax函数\n",
    "\n",
    "<img src=\"images/softmax.png\" />\n",
    "\n",
    "softmax函数的函数形式是:\n",
    "\n",
    "<img src=\"images/softmax-function.svg\" />\n",
    "\n",
    "softmax适合有多个输出神经元的网络, 并且期望只有一个神经元被激活, 也就是说, 输出神经元的激活量之和等于0, 这是softmax函数的被经常用于输出层的原因。\n",
    "\n",
    "##### 其他激活函数\n",
    "\n",
    "实际上还有很多激活函数我们没有举例, 而且上面列出的激活函数我们也没打算让你们立刻掌握, 他们需要在具体案例中进行说明, 你才能有一个感性认识, 所以目前情况来看, 如果你不理解这些激活函数, 可以先不用考虑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用keras实现简单感知机\n",
    "\n",
    "假设一个神经元有三个输入值$(x_1, x_2, x_3)$, 一个输出值, 这种情况适用于上一节讲到的用三个身体指标判断人的性别。使用Keras可以很快实现一个这样的神经网络。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model = Sequential()\n",
    "# 只有一个神经元, 三个输入数值\n",
    "model.add(Dense(1, input_dim=3, kernel_initializer='random_normal', name=\"Dense\"))\n",
    "# 激活函数使用sigmoid\n",
    "model.add( Activation('sigmoid', name=\"Activation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='images/simple-perception.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/simple-perception.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras实战\n",
    "\n",
    "使用keras实现如下网络结构, 并训练模型:\n",
    "\n",
    "<img src=\"images/nn.png\" />\n",
    "\n",
    "使用场景:\n",
    "\n",
    "输入值$(x_1, x_2, x_3)$代表人的身高体重和年龄, 输出值$(y_1, y_2)$分别是男生的概率和女生的概率。我们的目的是通过身体指标预测性别。\n",
    "\n",
    "#### 我们通过如下程序生成一个测试数据集:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 总人数是1000, 一半是男生\n",
    "n = 1000\n",
    "# 所有的身体指标数据都是标准化数据, 平均值0, 标准差1\n",
    "tizhong = np.random.normal(size = n) \n",
    "shengao = np.random.normal(size=n)\n",
    "nianling = np.random.normal(size=n)\n",
    "# 性别数据, 前500名学生是男生, 用数字1表示\n",
    "gender = np.zeros(n)\n",
    "gender[:500] = 1\n",
    "# 男生的体重比较重,所以让男生的体重+1\n",
    "tizhong[:500] += 1\n",
    "\n",
    "# 男生的身高比较高, 所以让男生的升高 + 1\n",
    "shengao[:500] += 1\n",
    "\n",
    "# 男生的年龄偏小, 所以让男生年龄降低 1\n",
    "nianling[:500] -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 只有一个神经元, 三个输入数值\n",
    "model.add(Dense(4, input_dim=3, kernel_initializer='random_normal', name=\"Dense1\"))\n",
    "# 激活函数使用softmax\n",
    "model.add( Activation('relu', name=\"hidden\"))\n",
    "# 添加输出层\n",
    "model.add(Dense(2, input_dim=4, kernel_initializer='random_normal', name=\"Dense2\"))\n",
    "# 激活函数使用softmax\n",
    "model.add( Activation('softmax', name=\"output\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编译模型\n",
    "\n",
    "需要指定优化器和损失函数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 235us/step - loss: 0.6743 - acc: 0.7180\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.6162 - acc: 0.7310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.5592 - acc: 0.7570\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.5162 - acc: 0.7680\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.4867 - acc: 0.7770\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.4663 - acc: 0.7830\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.4539 - acc: 0.7890\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 86us/step - loss: 0.4469 - acc: 0.7920\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.4431 - acc: 0.7940\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 88us/step - loss: 0.4407 - acc: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2022ef0e2b0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换成one-hot格式\n",
    "from keras import utils\n",
    "gender_one_hot = utils.to_categorical(gender, num_classes=2)\n",
    "# 身体指标都放入一个矩阵data \n",
    "data = np.array([tizhong, shengao, nianling]).T\n",
    "# 训练模型\n",
    "model.fit(data, gender_one_hot, epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "女生\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[0, 0, 0]])\n",
    "probability = model.predict(test_data)\n",
    "if probability[0, 0]>0.5:\n",
    "    print('女生')\n",
    "else:\n",
    "    print('男生')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关键词解释\n",
    "\n",
    "- input_dim: 输入的维度数\n",
    "- kernel_initializer: 数值初始化方法, 通常是正太分布\n",
    "- batch_size: 一次训练中, 样本数据被分割成多个小份, 每一小份包含的样本数叫做batch_size\n",
    "- epochs: 如果说将所有数据训练一次叫做一轮的话。epochs决定了总共进行几轮训练。\n",
    "- optimizer: 优化器, 可以理解为求梯度的方法\n",
    "- loss: 损失函数, 可以理解为用于衡量估计值和观察值之间的差距, 差距越小, loss越小\n",
    "- metrics: 类似loss, 只是metrics不参与梯度计算, 只是一个衡量算法准确性的指标, 分类模型就用accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
