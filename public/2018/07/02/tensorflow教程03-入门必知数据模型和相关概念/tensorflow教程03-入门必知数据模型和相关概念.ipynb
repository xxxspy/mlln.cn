{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: tensorflow教程03-入门必知数据模型和相关概念\n",
    "date: 2018-07-02 20:17:55\n",
    "tags: [tensorflow教程, 深度学习]\n",
    "toc: true\n",
    "xiongzhang: true\n",
    "mathjax: true\n",
    "\n",
    "---\n",
    "<span></span>\n",
    "<!-- more -->\n",
    "\n",
    "> 声明: 本文由[DataScience](http://mlln.cn)原创发表, 转载请注明[本文链接](http://mlln.cn)mlln.cn, 并在文后留言`转载`.\n",
    "\n",
    "本文代码运行环境:\n",
    "\n",
    "- windows10\n",
    "- python3.6\n",
    "- jupyter notebook\n",
    "- tensorflow 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在入门任何一门语言的时候我们都会首先介绍这个语言使用的数据模型, 数据模型相当于一门语言的基石, 所有的功能都是在对数据模型进行操作。TensorFlow中的数据模型由张量表示, 也就是tensor, 而名字\"tensorflow\"意义就是张量在图中的流动。为了避免复杂的数学定义，我们可以说一个张量（在TensorFlow中）标识了一个多维数值数组。该数据结构由三个参数 - 秩，形状和类型表征。下面我们一一介绍这三个概念, 并使用代码让你对这三个概念有一个感性认识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是张量的秩(Rank)\n",
    "\n",
    "每个张量由称为秩的维度单位描述。它标识张量的维数，因此，秩是已知的 - 作为张量的阶或维度。秩为零的张量是标量，秩为一的张量是向量，而秩为二的张量是矩阵。下面的代码定义了一个TensorFlow标量，一个向量，一个矩阵和一个三维张量(下面我们使用tf.constant创建一个张量, 但这并不表示张量只能由constant创建)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标量: ()\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# 你可以用constant创建一个张量\n",
    "scalar = tf.constant(100)\n",
    "# 向量\n",
    "vector = tf.constant([1,2,3,4,5])\n",
    "# 矩阵\n",
    "matrix = tf.constant([[1,2,3], [4,5,6]])\n",
    "# 立方\n",
    "cube_matrix = tf.constant([[[1],[2],[3]],[[4],[5],[6]],[[7],[8],[9]]])\n",
    "print('标量:', scalar.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量: (5,)\n"
     ]
    }
   ],
   "source": [
    "print('向量:', vector.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "print('矩阵:', matrix.get_shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "立方体: (3, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print('立方体:', cube_matrix.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是张量的形状(Shape)\n",
    "\n",
    "张量的形状是它所具有的行数和列数。现在我们看一下张量形状与张量秩的关系：\n",
    "\n",
    "- 张量的形状用`TensorShape`类来定义, 它可以被看做一个list或者tuple, 形状内的每个元素表示每个维度上的长度。比如向量的形状:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(5)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵的形状:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorfloa常见哪些数据类型(Data types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32位浮点数: <dtype: 'float32'>\n",
      "64位浮点数: <dtype: 'float64'>\n",
      "8位整数: <dtype: 'int8'>\n",
      "16位整数: <dtype: 'int16'>\n",
      "32位整数: <dtype: 'int32'>\n",
      "64位整数: <dtype: 'int64'>\n",
      "8位无符号整数: <dtype: 'uint8'>\n",
      "字符串: <dtype: 'string'>\n",
      "布尔值: <dtype: 'bool'>\n",
      "64位复数: <dtype: 'complex64'>\n",
      "128位复数: <dtype: 'complex128'>\n"
     ]
    }
   ],
   "source": [
    "print('32位浮点数:',tf.float32)\n",
    "print('64位浮点数:',tf.float64)\n",
    "print('8位整数:',tf.int8)\n",
    "print('16位整数:',tf.int16)\n",
    "print('32位整数:',tf.int32)\n",
    "print('64位整数:',tf.int64)\n",
    "print('8位无符号整数:',tf.uint8)\n",
    "print('字符串:',tf.string)\n",
    "print('布尔值:',tf.bool)\n",
    "print('64位复数:',tf.complex64)\n",
    "print('128位复数:',tf.complex128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，TensorFlow的这些API用于管理张量与NumPy数组之间的转换。要建立一个具有常数值的张量，将一个NumPy数组传递给tf.constant（）运算符，结果将是一个具有该值的TensorFlow张量, 并且数据类型保持一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr数据类型: int32        vec数据类型: <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([1,2,3,4,5,6])\n",
    "vec = tf.constant(arr)\n",
    "print('arr数据类型:', arr.dtype, '       vec数据类型:', vec.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是变量(Variable)\n",
    "\n",
    "变量通常代表可更新的参数, 是TensorFlow中的对象。变量必须被初始化;你也可以保存并恢复它来分析你的代码。变量由tf.Variable（）语句创建。在下面的例子中，我们学习率逐渐降低的过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.3\n",
      "0.20000002\n",
      "0.10000002\n",
      "1.4901161e-08\n"
     ]
    }
   ],
   "source": [
    "learning_rate = tf.Variable(0.5, name='Learning-Rate', dtype=tf.float32)\n",
    "step = tf.constant(-0.1, name='Step', dtype=tf.float32)\n",
    "update = tf.add(learning_rate, step)\n",
    "update = tf.assign(learning_rate, update,  'Update-LR')\n",
    "# 因为图中有变量, 所以需要初始化\n",
    "initialize_var = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(initialize_var)\n",
    "    for _ in range(5):\n",
    "        sess.run(update)\n",
    "        print(sess.run(learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 怎样获取计算图中张量的值\n",
    "\n",
    "获取节点张量的输出，通过调用会话对象的run（）函数来执行计算图，并传入要检索的张量。除了取单个张量节点外，还可以取多个张量。\n",
    "\n",
    "在交互式环境中, 我们通常使用`InteractiveSession`, 关于这个类的说明引用官方说法:\n",
    "\n",
    "> 使用InteractiveSession一个主要的变化是：运行在没有指定会话对象的情况下运行变量。这是与Session（）最大的不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mysites\\deeplearning.ai-master\\.env\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.3\n",
      "0.20000002\n",
      "0.10000002\n",
      "1.4901161e-08\n"
     ]
    }
   ],
   "source": [
    "learning_rate = tf.Variable(0.5, name='Learning-Rate', dtype=tf.float32)\n",
    "step = tf.constant(-0.1, name='Step', dtype=tf.float32)\n",
    "update = tf.add(learning_rate, step)\n",
    "update = tf.assign(learning_rate, update, name= 'Update-LR')\n",
    "# 因为图中有变量, 所以需要初始化\n",
    "initialize_var = tf.global_variables_initializer()\n",
    "sess.run(initialize_var)\n",
    "for _ in range(5):\n",
    "    update.eval()\n",
    "    print(learning_rate.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeds\n",
    "\n",
    "Feed机制(我不知道怎么翻译)功能就是用于向计算图中提供数据。它用张量值暂时替换计算图中的`tf.placeholder`所代表的张量。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "4.0\n",
      "9.0\n",
      "16.0\n",
      "25.0\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,3,4,5]\n",
    "x = tf.placeholder(tf.float32, shape=())\n",
    "y = tf.square(x)\n",
    "for d in data:\n",
    "    print(y.eval(feed_dict={x: d}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
