{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: 作文自动评分-位置编码position-encoding(PE)解释\n",
    "date: 2018-07-05 20:17:55\n",
    "tags: [tensorflow, 深度学习, 作文评分]\n",
    "toc: true\n",
    "xiongzhang: true\n",
    "mathjax: true\n",
    "\n",
    "---\n",
    "<span></span>\n",
    "<!-- more -->\n",
    "\n",
    "> 声明: 本文由[DataScience](http://mlln.cn)原创发表, 转载请注明[本文链接](http://mlln.cn)mlln.cn, 并在文后留言`转载`.\n",
    "\n",
    "本文代码运行环境:\n",
    "\n",
    "- windows10\n",
    "- python3.6\n",
    "- jupyter notebook\n",
    "- tensorflow 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### position-encoding\n",
    "\n",
    "这是用词向量计算句子向量的一种算法, 在[End-to-end Memory Network](https://arxiv.org/pdf/1503.08895.pdf)这篇论文中被提出来。在这篇论文中比较了另一种计算句子向量的模型--词袋模型, 下面我们分别来说一下这两种方法。\n",
    "\n",
    "#### 词袋模型\n",
    "\n",
    "假设我们用$x_{ij}$表示第i个句子的第j个词, 一个句子的所有词可以表示为$x_i = \\{x_{i1}，x_{i2}，...，x_{ij} \\}$，嵌入每个单词并对得到的向量求和：\n",
    "$$\n",
    "m_i = \\sum x_{ij}\n",
    "$$\n",
    "\n",
    "$m_i$就代表句子向量。这有一个缺点，就是它无法捕捉句子中单词的顺序，这对某些任务很重要。\n",
    "\n",
    "#### PE模型\n",
    "\n",
    "因此，我们提出了第二种表示方式，用于对单词中的单词位置进行编码句子。计算公式是这样的(Element Wise):\n",
    "\n",
    "$$\n",
    "m_i = \\sum l_i \\cdot x_{ij}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "l_i = (1 - j / J)-(k/d)(1 − 2j/J) = 1 + (2k/d-1) (2j/J - 1)\n",
    "$$\n",
    "\n",
    "注意其中符号的意义:\n",
    "\n",
    "- i: 第i个句子\n",
    "- j: 第j个词\n",
    "- J: 句子长度\n",
    "- k: 向量的第k个元素\n",
    "- d: 向量维度\n",
    "\n",
    "用代码实现的话就是:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def position_encoding(sentence_size, embedding_size):\n",
    "    \"\"\"\n",
    "    Position Encoding \n",
    "    \"\"\"\n",
    "    # sentence_size = J\n",
    "    # embedding_size = d\n",
    "    # i = k\n",
    "    # j = j\n",
    "    J = sentence_size\n",
    "    d = embedding_size\n",
    "    encoding = np.ones((embedding_size, sentence_size), dtype=np.float32)\n",
    "    ls = sentence_size+1\n",
    "    le = embedding_size+1\n",
    "    for k in range(1, le):\n",
    "        for j in range(1, ls):\n",
    "            encoding[k-1, j-1] = (2*k/d-1)*(2*j/J - 1)\n",
    "    encoding += 1\n",
    "    return np.transpose(encoding)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者我在其他论文里见过别人这样做, 但是我还没搞清楚原因, 如果你知道, 请留言告诉我。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def position_encoding(sentence_size, embedding_size):\n",
    "    \"\"\"\n",
    "    Position Encoding described in section 4.1 [1]\n",
    "    \"\"\"\n",
    "    encoding = np.ones((embedding_size, sentence_size), dtype=np.float32)\n",
    "    ls = sentence_size+1\n",
    "    le = embedding_size+1\n",
    "    for i in range(1, le):\n",
    "        for j in range(1, ls):\n",
    "            encoding[i-1, j-1] = (i - (le-1)/2) * (j - (ls-1)/2)\n",
    "    encoding = 1 + 4 * encoding / embedding_size / sentence_size\n",
    "    return np.transpose(encoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献\n",
    "\n",
    "Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. 2015. End-To-End Memory Networks. In Advances in Neural Information Processing Systems 28, C Cortes, N D Lawrence, D D Lee, M Sugiyama, and R Garnett (Eds.). Curran Associates, Inc., 2440–2448."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
